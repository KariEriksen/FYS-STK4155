\documentclass[a4paper, twocolumn]{article}

% Included packages ---------------------------------------------------------- %
\usepackage{lipsum}                          % Generate random, blind, filler-text.
\usepackage[utf8]{inputenc}                  % utf-8 encoding, æ, ø , å, etc.
\usepackage{a4wide}                          % Adjust margins to better fit A4 format.
\usepackage{array}                           % Matrices.
\usepackage{dsfont}                          % Math symbols.
\usepackage{amsmath}                         % Math symbols, and enhanced matrices.
\usepackage{amsfonts}                        % Math fonts.
\usepackage{amssymb}                         % Additional symbols.
\usepackage{mathrsfs}                        % Most additional symbols.
\usepackage[pdftex]{graphicx}                % Improved inclusion of .pdf-graphics files.
\usepackage{sidecap}                         % Floats with captions to the right/left.
\usepackage{enumerate}                       % Change counters (arabic, roman, etc.).
\usepackage{floatrow}                        % Multi-figure floats.
\usepackage{subfig}                          % Multi-figure floats.
\usepackage{bm}                              % Bolded text in math mode.
\usepackage[framemethod=default]{mdframed}   % Make boxes.
\usepackage{listings}                        % For including source code.
\usepackage{mathtools}                       % Underbrackets, overbrackets.
\usepackage[dvipsnames]{xcolor}              % Colors.
\usepackage{capt-of}                         % Caption things which are not floats.
\usepackage{algorithm2e}                     % Algorithm non-float which we can caption by \captionof{algocf}{<caption>}.
\usepackage{fontawesome}                     % Github icon, etc. \faGithub
\usepackage{sidecap}                         % Floats with captions on the side.
\usepackage{tabularx}                        % Tables and stuff.
\usepackage{tabulary}                        % Tables and stuff.
\usepackage[sf,sl,outermarks]{titlesec}      % Change fonts in section{}, subsection{}, etc.
\usepackage[subfigure]{tocloft}              % Change spacing between numbers and titles in TOC.
\usepackage{pgfplots}                        % Making Tikz plots.
\usepackage{booktabs}                        % \toprule, \midrule, etc. for tables.
\usepackage{siunitx}                         % Allows S table column, aligning on decimal point.
\usepackage{chngcntr}                        % Change counter behaviour, supress increment of sub counters.
\usepackage{tikz}                            % Draw complicated pictures in a super hard way.
\usepackage{cuted}                           % Place long equations in @twocolumn over entire page.
\usepackage[version=4]{mhchem}               % Chemical reaction equations using \ce{...}.
\usepackage[%                                % Adds functionality to captions.
  tableposition = top,
  labelsep      = period,
  justification = raggedright,
  format        = hang,
  ]{caption}                                 
\usepackage[%                                % Interactive references and links, colored.
  colorlinks  = true,
  linkcolor   = black,
  urlcolor    = blue,
  citecolor   = black,
  linktocpage = true,
  ]{hyperref}            
\usepackage[%                                % References, in super-script form.
  autocite    = superscript,
  backend     = biber,
  sortcites   = true,
  style       = numeric-comp,
  sorting     = none,
  url         = false,
  ]{biblatex}
\usepackage[autostyle, english = american]{csquotes} % Assure quotation marks are inserted correctly aligned left/right.
\MakeOuterQuote{"}

% Package settings ----------------------------------------------------------- %
\renewcommand{\thesection}{\Roman{section}}         % I, II, III, IV, etc. section numbering
\renewcommand{\thesubsection}{\Alph{subsection}}    % A, B, C, etc. subsection numbering
\renewcommand{\thesubsubsection}{}                  % Remove subsubsection numbering.
\floatsetup[table]{capposition=top}                 % Place table captions above the table.
\captionsetup[subfigure]{labelformat=empty}         % Remove the (a), (b), etc. tags from subfigures.
\advance\cftsecnumwidth 1.0em\relax                 % Set the spacing between section headings and titles in TOC with tocloft.
\advance\cftsubsecindent 1.0em\relax                % Set the spacing between subsection headings and titles in TOC with tocloft.
\advance\cftsubsecnumwidth 1.0em\relax              % Set the spacing between subsubsection headings and titles in TOC with tocloft.
\newcommand{\listingsfont}{\ttfamily}
\newcommand{\inlinepy}[1]{\lstinline[language={python}]{#1}}
\newcommand{\inlinecc}[1]{\lstinline[language={c++}]{#1}}
\counterwithout*{subsection}{section}               % Dont reset the subsection counter on new \section{} calls.
\renewcommand{\figurename}{FIG.}                    % Captions of figures read FIG.
\renewcommand{\tablename}{TABLE}                    % Captions of tables read TABLE 
\renewcommand{\thetable}{\Roman{table}}             % Number tables with roman numerals.
\usetikzlibrary{matrix}                             % Some tikz picture library things.
\usetikzlibrary{arrows.meta, calc, chains, positioning}
\definecolor{listingsbackgroundcolor}{rgb}{0.975,0.975,0.975}
\colorlet{shadecolor}{listingsbackgroundcolor}



% Section headings settings -------------------------------------------------- %
\titleformat{\section}[hang]  % {command}[shape]
  {\normalfont\bfseries}      % {format}
  {\thesection.}              % {label}
  {2ex}                       % {sep}
  {\centering\MakeUppercase}  % {before-code}[after-code]

\titleformat{\subsection}[hang] % {command}[shape]
  {\normalfont\bfseries}        % {format}
  {\thesubsection.}             % {label}
  {1ex}                         % {sep}
  {\centering}                  % {before-code}[after-code]

\titleformat{\subsubsection}[hang]  % {command}[shape]
  {\normalfont\bfseries}            % {format}
  {}                                % {label}
  {1ex}                             % {sep}
  {\centering}                      % {before-code}[after-code]


% References ----------------------------------------------------------------- %
\newcommand{\Fig}[1]{Fig.\ \ref{fig:#1}}
\newcommand{\fig}[1]{Fig.\ \ref{fig:#1}}
\newcommand{\eq} [1]{Eq.\ (\ref{eq:#1})}
\newcommand{\Eq} [1]{Eq.\ (\ref{eq:#1})}
\newcommand{\tab}[1]{Table \ref{tab:#1}}
\newcommand{\Tab}[1]{Table \ref{tab:#1}}

% Matrices ------------------------------------------------------------------- %
\newcommand{\mat} [2]{\begin{matrix}[#1] #2 \end{matrix}}    % Nothing enclosing it.
\newcommand{\pmat}[2]{\begin{pmatrix}[#1] #2 \end{pmatrix}}  % Enclosing parentheses.
\newcommand{\bmat}[2]{\begin{bmatrix}[#1] #2 \end{bmatrix}}  % Enclosing square brackets.
\newcommand{\vmat}[2]{\begin{vmatrix}[#1] #2 \end{vmatrix}}  % Enclosing vertical bars.
\newcommand{\Vmat}[2]{\begin{Vmatrix}[#1] #2 \end{Vmatrix}}  % Enclosing double bars.

% Manually set alignment of rows / columns in matrices (mat, pmat, etc.) ----- %
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother

% figures in multicols environment ------------------------------------------- %
\newenvironment{Figure}
  {\par\medskip\noindent\minipage{\linewidth}}
  {\endminipage\par\medskip}

% Set bibliography file and path for images.
\addbibresource{../ref/project3-references.bib}
\bibliography{../ref/project3-references.bib}
\graphicspath{{../figures/}}

% Black frame with gray background ------------------------------------------ %
\definecolor{gray}{gray}{0.9}
\newmdenv[linecolor=white,backgroundcolor=gray]{grayframe}
\newmdenv[linecolor=white,backgroundcolor=shadecolor]{shadeframe}

% Title
\title{{\sc Solving partial differential equations with neural networks \\ {\large FYS-STK4155: Project 3}}}
\author{Morten Ledum, Håkon Kristiansen \& Kari Eriksen \\ \faGithub \ {\small \href{https://github.com/mortele/FYS-STK4155/tree/master/project3}{github.com/mortele/FYS-STK4155}}}
% ---------------------------------------------------------------------------- %
% ---------------------------------------------------------------------------- %
\begin{document}

\onecolumn
\maketitle

\begin{abstract}
\lipsum[1]
\end{abstract}

\twocolumn
\onecolumn

\tableofcontents 
\twocolumn


\section{Introduction}
\lipsum[1]

\section{Theory}
\lipsum[2]

\subsection{The heat equation}
The heat equation is a partial differential equation (in space $x$ and time $t$) which describes the evolution of temperature differences in a region of space over a time interval. It is based on \textit{Fourier's law}; the rate of heat flow through a surface is proportional to the temperature gradient across the surface, i.e.\
\begin{align}
\mathbf{q}=-k\nabla T = -k \frac{\partial T}{\partial x},
\end{align}
where $\mathbf{q}$ denotes the heat flux density, $k$ is the thermal conductivity of the surface material, and $T$ represents the temperature. Changes in temperature are proportional to changes in internal energy, with the proportionality constant being the specific heat capacity $c_p$. With the arbitrary energy zero point placed at absolute zero, this can be written as
\begin{align}
Q = c_p \rho T,
\end{align}
with $Q$ being the internal energy and $\rho$ denoting the mass density. This is essentially just a restatement of (a shifted) \textit{first law of thermodynamics}, in the absence of applied work. The total heat energy contained in a region $[a,b]$ is given by the integral
\begin{align}
\int_a^b\mathrm{d}x\,c_p\rho T(x,t).
\end{align}
Integrating over a small region of space and considering the change in internal energy over a short time interval (assuming $c_p$ and $\rho$ are both time-independent and spatially homogenous) gives 
\begin{align}
\Delta Q=& c_p \rho\int_{x}^{x+\Delta x}\mathrm{d}\chi\,\Big[T(\chi,t+\Delta t) - T(\chi,t)\Big] \nonumber \\
&= c_p\rho \int_x^{x+\Delta x}\mathrm{d}\chi\int_{t}^{t+\Delta t}\mathrm{d}\tau\,\frac{\partial T}{\partial \tau}. \label{eq:energy1}
\end{align}
Over a short time period $\Delta t$, the change in internal energy of a short segment of length $\Delta x$  must be entirely due to the heat flux in/out of the boundaries,
\begin{align}
\Delta Q &= k\int_t^{t+\Delta t}\mathrm{d}\tau\,\left[\frac{\partial T(x+\Delta x,\tau)}{\partial x} - \frac{\partial T(x,\tau)}{\partial x} \right] \nonumber \\
%
&= k\int_t^{t+\Delta t}\mathrm{d}\tau\int_x^{x+\Delta x}\mathrm{d}\chi\,\frac{\partial^2 T}{\partial \chi^2}. \label{eq:energy2}
\end{align}
By conservation of energy, the difference between \eq{energy1} and \eq{energy2} must obviously vanish. Since we are integrating over the same spatial and temporal regions in both equations, this means that the integrand must vanish identically:
\begin{align}
\frac{k}{c_p\rho} \frac{\partial^2 T}{\partial x^2} = \frac{\partial T}{\partial t}. \label{eq:heat}
\end{align}
This is known as the \textit{heat equation} and is a special case of the more general diffusion equation. 

\subsection{Closed form solution}
The 1D heat equation may be solved by applying a separation of variables ansatz, i.e.\ we assume the solution $u(x,t)$ takes the form
\begin{align}
u(x,t) = X(x)T(t), 
\end{align}
with $X(x)$ carrying all the $x$-dependence, and $T(t)$ carrying the corresponding time dependence. Introducing the compact notation 
\begin{align}
u_{x} \equiv \partial_x u =  \frac{\partial u}{\partial x}, \ \ \text{ and } \ \ u_t \equiv \partial_t u =  \frac{\partial u}{\partial t}, 
\end{align}
we find by insertion of the ansatz into \eq{heat}:
\begin{align}
\alpha^2\, u_{xx} &= u_t \nonumber \\
%
\alpha^2\, \partial_x \Big[\partial_x  X(x)T(t) \Big] &= \partial_t X(x)T(t) \nonumber \\
%
\alpha^2\, \partial_x \Big[ X_x T + XT_x \Big] &= X_tT+XT_t \nonumber \\
%
\alpha^2\, \Big[X_{xx}T + 2X_xT_x + XT_{xx}\Big]&= XT_t \nonumber \\
\frac{1}{X(x)} \frac{\partial^2 X(x)}{\partial x^2} &= \frac{1}{\alpha^2\,T(t)}\frac{\partial T(t)}{\partial t},
\end{align}
where we defined $\alpha^2\equiv k/c_p\rho$ and used the fact that $X_t=T_x=0$. As the left hand side is independent of $t$ and the right hand side is independent of $x$, the equality can only be achieved if both sides are constant. This reduces the original partial differential equation into a set of two ordinary differential equations 
\begin{align}
\frac{1}{X(x)}\frac{\partial^2X(x)}{\partial x^2}&=k  \label{eq:X(x)}\\
%
\frac{1}{\alpha^2\,T(t)}\frac{\partial T(t)}{\partial t}&=k, \label{eq:T(t)}
\end{align} 
with $k$ an undetermined constant. 

Depending on the value of $k$, the spatial part has solutions $X(x)=Ax+B$ (if $k=0$), $X(x)=A\mathrm{e}^{\mu x}+B\mathrm{e}^{-\mu x}$ (if $k=\mu^2>0$), or $X(x)=A\mathrm{e}^{\mathrm{i}\mu x}+B\mathrm{e}^{-\mathrm{i}\mu x}$ (if $k=-\mu^2<0$). The temporal equation has solutions $T(t)=C$ (if $k=0$), or $T(t)=C\mathrm{e}^{\alpha^2\mu^2 x}$ (otherwise).

\subsubsection{Applying the boundary conditons}
In order to make progress, we need to apply the specific boundary and initial conditions. In our case, the boundaries at $x=0$ and $x=L=1$ vanish, and the initial spatial solution takes the form $u(x,t=0)=\sin \pi x$. If the $k$ constant of \eq{X(x)} vanishes, then  both constants $A$ and $B$ vanish due to the boundary conditions. The same is true if $k=\mu^2>0$. It follows that the only non-trivial solutions arise when $k=-\mu^2<0$, in which case we find (left boundary)
\begin{align}
X(0) &= A\cos \mu x + B\sin\mu x = 0 \Rightarrow A=0 \nonumber 
\end{align}
and (right boundary) 
\begin{align}
X(1) &= B\sin\mu x = 0 \Rightarrow \mu=\pi n. \nonumber 
\end{align}
This gives rise to an infinite set of equations\textemdash one for each $n$\textemdash which determine the Fourier coefficients of the initial condition $u(x,t=0)$:
\begin{align}
u(x,t=0) &= \sum_{n=1}^\infty B_n \sin (n\pi x),
\end{align}
with 
\begin{align}
B_n &= 2\int_0^1\mathrm{d}x\, u(x,t=0)\,\sin(n\pi x).
\end{align}

The temporal equation, \eq{T(t)}, can now be solved only applying the boundary conditions. With the value of $\mu$ fixed at $\mu=n\pi$, we obtain 
\begin{align}
T(t) = \mathrm{e}^{-n^2\pi^2\alpha^2 t}.
\end{align}

\subsubsection{Applying the initial condition}
Combining the $X(x)$ and $T(t)$ solutions we obtain a series representation of the solution in terms of the Fourier coefficients of the initial condition $u(x,t=0)$, in which the higher frequency modes of the initial solution decays more rapidly than the corresponding lower frequency modes,
\begin{align}
u(x,t) = \sum_{n=1}^\infty B_n \sin(n\pi x)\,\mathrm{e}^{-n^2\pi^2\alpha^2 t}. \label{eq:general}
\end{align}
It is easy to see that the steady-state solution is achieved when $u(x,t)=0$, since both boundaries (left and right) act as sinks for the initial heat energy contained in the system, and no heat is ever \textit{added}. In our case, the initial condition makes the general solution \eq{general} take on a very simple form. Applying $u(x,t=0)=\sin \pi x$, it is trivial to evaluate 
\begin{align}
B_n &= 2\int_0^1\mathrm{d}x\, \sin(\pi x)\, \sin(n\pi x) = \delta_{1n},
\end{align}
due to the orthogonality of $\sin(n\pi x)$ and $\sin(m\pi x)$. This means $B_1=1$ and $B_2,B_3,\dots = 0$,
and the full solution to \eq{heat} is given by 
\begin{align}
u(x,t)=\sin(\pi x)\,\mathrm{e}^{-\pi^2\alpha^2 t}. \label{eq:full}
\end{align}

\subsection{Explicit scheme}
One of the more simple methods in the world of solving ordinary and partial differential equation numerically is the explicit scheme. This is a method that bases itself upon using the previous value of the derivatives in order to find the new ones.
We will here derive the explicit scheme for the diffusion equation, \eq{diffusion}.
\begin{equation} \label{eq:diffusion}
\frac{\partial^2 u(x,t)}{\partial x^2} = \frac{\partial u(x,t)}{\partial t}
\end{equation}
We begin with Taylor expantion of $u(x,t)$ in $t$. 
\begin{equation*}
u(x,t + \Delta t) = u(x,t) + \Delta t u'(x,t) + \frac{1}{2} \Delta t^2 u''(x,t) + ...
\end{equation*}
Truncating the series after the first term we get an expression of the first derivative of $u$ wrt. $t$ with the truncation error $O(\Delta t)$.
\begin{equation*}
u'(x,t) = \frac{u(x,t + \Delta t) - u(x,t)}{\Delta t} + O(\Delta t)
\end{equation*}
This can be simplyfied if we rewrite the derivative of $u$ wrt. $t$ as $u_t$ and discretize.
\begin{align*}
u_t &\approx \frac{u(x_i, t_j + \Delta t) - u(x_i, t_j)}{\Delta t} \\
&\approx \frac{u_{i,j+1} - u_{i,j}}{\Delta t}
\end{align*}
This is called the forward Euler method, we move one step forward in time in the integration process using the previous step. This is the simplest version of the explicit scheme.
Now we carry out the same procedure for the spatial part.
\begin{align*}
u(x + \Delta x,t) &= u(x,t) + \Delta x u'(x,t) + \frac{1}{2} \Delta x^2 u''(x,t) \\
&+ \frac{1}{3!} \Delta x^3 u'''(x,t) + ... \\
u(x - \Delta x,t) &= u(x,t) - \Delta x u'(x,t) + \frac{1}{2} \Delta x^2 u''(x,t) \\
&- \frac{1}{3!} \Delta x^3 u'''(x,t) + ... 
\end{align*}
%\begin{align}
%\Delta x u'(x,t) &= u(x + \Delta x,t) - u(x,t) - \frac{1}{2} \Delta x^2 u''(x,t) \\
%\Delta x u'(x,t) &= -u(x - \Delta x,t) + u(x,t) + \frac{1}{2} \Delta x^2 u''(x,t)
%\end{align}
%\begin{equation*}
%u''(x,t) = \frac{u(x + \Delta x,t) - 2u(x,t) + u(x - \Delta x,t)}{\Delta x^2} + O(\Delta x^2)
%\end{equation*}
We truncate at second term in order to get the second order derivative and rewrite to simplify as before. 
\begin{align*}
u_{xx} &\approx \frac{u(x_i + \Delta x,t_j) - 2u(x_i,t_j) + u(x_i - \Delta x,t_j)}{\Delta x^2} \\
&\approx \frac{u_{i+1, j} - 2u_{i,j} + u_{i-1,j}}{\Delta x^2}
\end{align*}
This is a centered difference method as we are using both previous and latter values in space to find the new second derivative of the spatial coordinate.
Adding the two solutions into the original differential equation we get the following. 
\begin{align*}
u_t &= u_{xx} \\
u_{i,j+1} - u_{i,j} &= u_{i+1,j} - 2u_{i,j} + u_{i-1,j} \frac{\Delta t}{\Delta x^2}
\end{align*}
The full diffusion equation on discretized form can further be rewritten by putting $\beta = \Delta t / \Delta x^2$.
\begin{align*}
u_{i, j+1} &= \beta (u_{i+1,j} - 2u_{i,j} + u_{i-1,j}) + u_{i,j} \\
&= \beta (u_{i+1,j} + u_{i-1,j}) + (1 - 2\beta)u_{i,j} 
\end{align*}

\subsection{Finite difference method} \label{sect:finitediff}
The most straightforward way to solve \eq{heat} numerically is through \textit{finite difference methods}, i.e.\ discretizing time and space on a grid and Taylor expanding the solution to obtain algebraic equation sets. A multitude of different strategies and schemes exists, but we will consider the \textit{explicit forward Euler} scheme. 

The spatial region $[0,L]$ is discretized by splitting it into $N$ segments, and considering only the functional values on the points $x_i=i\Delta x$ with $i\in[0,N-1]$. We denote a function $f(x,t)$ evaluated at $x_i$ (and at time $t$) by $f_i^t=f(x_i,t)$. Considering $N$ spatial points gives a step size $\Delta x$ between each point of 
\begin{align}
\Delta x = \frac{L}{N-1}.
\end{align}
In addition, we introduce a discretization in the temporal dimension with step size $\Delta t$. 

Let us consider the Taylor expansion of a function $f(x,t)$ considered at fixed $t$, $f(x;t)$, around a spatial point $x$. We use the shorthand $h\equiv (x-a)$, and consider the expansion at a point $a\not=x$. The expansions of $f(x+h;t)$ and $f(x-h;t)$ are given by, 
\begin{align}
f(x+h) &\approx f(x) + hf'(x) + h^2f''(x), \label{eq:f(x+h)}\\
f(x-h) &\approx f(x) - hf'(x) + h^2f''(x), \label{eq:f(x-h)}
\end{align}
respectively. As $t$ is considered a fixed parameter for the moment, we supressed the second functional argument for notational brevity. The shorthand $f'(x)$ is here used to denote differentiation w.r.t.\ $x$. Note that both equations hold with equality if an overall error term proportional to $h^3$ is added on the right hand side, i.e.\ $\mathcal{O}(h^3)$. Adding Eqs. (\ref{eq:f(x+h)}) and (\ref{eq:f(x-h)}) and dividing through by $h^2$ yields
\begin{strip}
\begin{align}
f(x+h)+f(x-h) &= 2f(x) + h^2f''(x) + \mathcal{O}(h^4) \nonumber \\
%
f''(x) &= \frac{f(x+h)-2f(x)+f(x-h)}{h^2} + \mathcal{O}(h^2), \label{eq:centraldiff}
\end{align}
\end{strip}
which is the three-point central difference approximation to the second derivative. Note that the resulting error is proportional to $h^2$ because the third order contributions from Eqs. (\ref{eq:f(x+h)}) and (\ref{eq:f(x-h)})\textemdash $h^3f'''(x+h)$ and $-h^3f'''(x+h)$\textemdash cancel exactly. A corresponding temporal first order derivative approximation may be found by simply considering \eq{f(x+h)}, and considering $h$ to be a small temporal step, $x$ to be a fixed parameter, and varying $t$. This gives
\begin{align}
f'(t)&= \frac{f(t+h)-f(t)}{h}+\mathcal{O}(h), \label{eq:forwarddiff}
\end{align}
where the error term is proportional to $h^2$ when disregarding the last term on the right hand side of \eq{f(x+h)}, which gives $\mathcal{O}(h)$ after dividing through by $h$.

Let us now consider \eq{centraldiff} on the previously defined grid, and take $h=\Delta x$. In the \eq{forwarddiff} case, we define $h=\Delta t$, and equate $\alpha^2\,f''(x)$ with $f'(t)$ as in the heat equation \eq{heat}. The result can be solved for $f(x,t+\Delta t)$, i.e.\ the \textit{next} time step given that the previous step is known:
\begin{align}
\frac{f_i^{j+1} - f_i^j}{\Delta t} &= \alpha^2\frac{f_{i+1}^j - 2f_i^j + f_{i-1}^j}{\Delta x^2} \nonumber \\
%
f_i^{j+1} &= f_i^j + \beta \Big[f_{i+1}^j - 2f_i^j + f_{i-1}^j\Big], \label{eq:explicit}
\end{align}
where $f_i^j$ denotes the discretized $f(x_i,t_j)$ and 
\begin{align}
\beta\equiv\alpha^2\left(\frac{\Delta t}{\Delta x^2}\right).
\end{align}
Equation (\ref{eq:explicit}) is known as the \textit{explicit Euler} scheme, and can be solved directly for $f(x,t+\Delta t)$ since the right hand side is all known at time step $t$.


\subsection{Implicit schemes}
As noted in section \ref{sect:finitediff}, applying the forward difference approximation for the first derivative in time\textemdash derived from the Taylor expansion of a function around the point $x+h$\textemdash yields the explicit Euler scheme. However, as we will see in section \ref{sect:finitestability}, the forward method has a rather weak stability criterion which neccessitates the use of very small time steps to ensure the solution remains well-behaved. 

If we instead employ a backward difference approximation in time (solving \eq{f(x-h)} for an $\mathcal{O}(h)$ approximation of the first derivative) we obtain equations sets which are stable for any combination of $\Delta x$ and $\Delta t$. This allows us to use more reasonable time steps and ultimately speeds up and improves the computed solution. 

However, using this approximation,
\begin{align}
f'(t)=\frac{f(t)-f(t-h)}{h}+\mathcal{O}(h), \label{eq:backwarddiff}
\end{align}
introduces additional complexity in that we are no longer able to simply solve for the unknown $f(x,t+\Delta t)$ in the resulting heat equation approximation. Equating Eqs. (\ref{eq:centraldiff}) and (\ref{eq:backwarddiff}) yields the \textit{implicit Euler} scheme:
\begin{align}
\frac{f_i^{j} - f_i^{j-1}}{\Delta t} &= \alpha^2\frac{f_{i+1}^j - 2f_i^j + f_{i-1}^j}{\Delta x^2} \nonumber \\
%
f_i^{j-1}&= -\beta \big[f_{i+1}^j + f_{i-1}^j\big] + \big(1+2\beta\big)f_i^j.
\end{align}
We note that the only known quantity is the left hand side $f_i^{j-1}=f(x,t-\Delta t)$, which means we must solve all the equations for every spatial point $i$ simultaneously in order to ensure they are all satisfied. This gives rise to a matrix-vector equation in the place of the single algebraic equation needed for the explicit scheme. Denoting $\gamma\equiv 1+2\beta$ we may write the equation set corresponding to the integration from $t-\Delta t$ to $t$ as
\begin{align}
A\mathbf{f}^j&=\mathbf{f}^{j-1},
\end{align}
with (zeros ommitted)
\begin{align}
A = \begin{pmatrix}
\gamma & -1 & \\
-1 & \gamma & -1 \\
 & -1 & \gamma & -1 \\
 & & &  \ddots \\
 & & & -1 & \gamma & -1 \\
 & & & & -1 & \gamma 
\end{pmatrix}
\end{align}
and
\begin{align}
\mathbf{f}^j
\begin{pmatrix}
f_0^{j} \\
f_1^{j} \\
f_2^{j} \\
\vdots \\
\mathbf{f}_N^{j}
\end{pmatrix}, \ \ \ 
f^{j-1}=\begin{pmatrix}
f_0^{j-1} \\
f_1^{j-1} \\
f_2^{j-1} \\
\vdots \\
f_N^{j-1}
\end{pmatrix} 
\end{align}
As the matrix $A$ is tri-diagonal, efficient linear scaling solution algorithms exists which circumvent the traditional solution schemes, e.g.\ LU decomposition at $\mathcal{O}(N^3)$.

\subsection{The Crank-Nicolson scheme}
\lipsum[3]

\subsection{Stability analysis \label{sect:finitestability}}
\lipsum[4]


\subsection{Finite element methods}
In the case of the finite difference approximation, the derivatives in the original partial differential equation is transformed into a set of algebraic equations by application of \textit{finite difference} approximations arising from Taylor expansions of the solution function. A fundamentally different, and somewhat more sophisticated, solution strategy entails writing the original differential equation in its \textit{weak form}. This is done by integrating the original equation multiplied by a test function $v(x)$ over the domain in question. Such a \textit{finite element} approach is normally accompanied by a simple finite element scheme in time when partial differential equations are considered. 

\subsubsection{Functional spaces and weak forms}
Let us consider the vector space of \textit{all} functions $f:\mathds{R}^2\rightarrow\mathds{R}$, which we will call $A(\mathds{R}^2)$. Obviously, the solution to the heat equation is contained in this space, being a real-valued function of two parameters, $x$ and $t$. However, we may consider subspaces with more useful structure than the all-encompassing $A(\mathds{R}^2)$. Assuming the initial and boundary conditions are specified in a sufficiently non-pathological way, the solution at each instant in time will be continous across the spatial integration domain, $\Omega$. In other words, the solution (at some $\tau\ge0$) $u(x;\tau)\in C(\Omega)$: The vector space of \textit{continous} functions $f:\Omega\rightarrow\mathds{R}$. As the heat equation involves a second spatial derivative, we might assume that the solution be twice continously differentiable, i.e.\ $u(x;\tau)\in C^2(\Omega)$.

It turns out that demanding $u\in C^2(\Omega)$ is too strict a bound on the behaviour of the solution. For example, a valid solution may be \textit{not} differentiable on a subset $S\subset\Omega$ with measure zero\footnote{A set $S\subset\mathds{R}$ of measure zeros is a set with vanishing "size," e.g.\ a finite set of \textit{points}.}, known as differentiable almost everywhere (a.e.). It is more useful to consider \textit{weakly differentiable} functions, which encompass the ordinary (strongly) differentiable functions and includes other possible solutions of partial differential equations. 

Equipping our functional space with the $L^1$ integral inner product (and the associated norm), consider a family of functions $\phi\in C^\infty(\Omega)$, with $\phi(\partial\Omega)=0$, where we denote by $\partial\Omega$ the boundary of the integration domain (in one dimension, this is just the end two points). The weak derivative of $u$ is defined as a function $v$ for which the following holds
\begin{align}
\int_\Omega \mathrm{d}x\, 
\end{align}


\subsection{Solving differential equations with neural networks}
The main focus on this project is exploring partial differential problems with the use of deep learning. Deep neural networks (DNN) are networks that consist of two hidden layers or more. In this part of the project we will be using Googles open-source library Tensorflow. A time consuming part of neural networks is the backpropagation and its equations. By using Tensorflow we avoid having to solve the derivatives of a cost function w.r.t to all the different weights and biases. It also provides us with a wast amount of applications. Different activation functions, gradients, loss function etc. And it is easy to add layers and nodes. 

Our biggest job becomes finding a cost function, and testing for different architectural layouts. We will look at a standard DNN with $n_h$ hidden layers. Each layer may contain different number of neurons, or nodes. 

As optimizer we will use stochastic gradient descent which also have been explained to some extent in previous reports. 

Since our PDE is the diffusion equation it makes sense to use the mean squared error (MSE) as our cost function. We want to minimize the right hand side of \eq{diff_0} which the MSE allow us to do. 

\begin{equation} \label{eq:diff_0}
0 = \frac{\partial u(x,t)}{\partial t} - \frac{\partial^2 u(x,t)}{\partial x^2} 
\end{equation}

\begin{equation}
MSE = \frac{1}{n} \sum^n \left( \frac{\partial u}{\partial t} - \frac{\partial^2 u}{\partial x^2} \right)^2
\end{equation}

Our next task is designing a trial function that can be used as input for the cost function. Preferably a trial function that satisfy the initial conditions and boundary conditions. If we look at \eq{trial} we see that for $x = 0$ and $x = 1$ the trial function is zero since $\sin (0) = \sin (\pi) = 0$ which is the boundary conditions. For $t = 0$ it is $\sin(\pi x)$ which is the initial condition. And \eq{trial} fulfilles all conditions.

\begin{equation} \label{eq:trial}
u_{trial}(x,t) = \sin (\pi x) + x(1 - x)tN(x, t, P)
\end{equation}

We can now begin training the network. Usually one would have one set of training data and one set of test data and compare the results. However we have an exact solution and can check our results directly. 

adjust $\alpha$ and look at the solution, and see how well the fit is

Or compare analytical with dnn solution for different time steps.


\section{Results and discussion}
\lipsum[6]

\section{Conclusion}
\lipsum[7]


\onecolumn{
\printbibliography
}

\end{document}



